{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RDF Conversion Workflow Demo\n",
    "\n",
    "This notebook demonstrates converting PMC XML articles to RDF for integration with knowledge graphs.\n",
    "\n",
    "## Use Cases\n",
    "\n",
    "- **Semantic Integration**: Integrate scientific literature with knowledge graphs\n",
    "- **SPARQL Queries**: Query literature data using SPARQL\n",
    "- **Ontology Alignment**: Align to standard ontologies (BIBO, FOAF, DCT)\n",
    "- **GraphDB Loading**: Prepare data for triple stores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required modules\n",
    "from pyeuropepmc.processing.fulltext_parser import FullTextXMLParser\n",
    "from pyeuropepmc.builders import build_paper_entities\n",
    "from pyeuropepmc.mappers import RDFMapper\n",
    "from rdflib import Graph, Namespace\n",
    "from rdflib.namespace import RDF, RDFS\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load and Parse a PMC XML File\n",
    "\n",
    "Let's start by loading a real PMC article:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded XML file: 64374 characters\n"
     ]
    }
   ],
   "source": [
    "# Load a fixture file\n",
    "fixture_path = \"../tests/fixtures/fulltext_downloads/PMC3359999.xml\"\n",
    "\n",
    "if os.path.exists(fixture_path):\n",
    "    with open(fixture_path, 'r') as f:\n",
    "        xml_content = f.read()\n",
    "    print(f\"Loaded XML file: {len(xml_content)} characters\")\n",
    "else:\n",
    "    print(f\"File not found: {fixture_path}\")\n",
    "    print(\"Please adjust the path to point to a PMC XML file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paper: Risk Factors of Porcine Cysticercosis in the Eastern Cape Province, South Africa\n",
      "PMCID: 3359999\n",
      "DOI: 10.1371/journal.pone.0037718\n",
      "\n",
      "Statistics:\n",
      "  Authors: 8\n",
      "  Sections: 10\n",
      "  Tables: 2\n",
      "  References: 28\n"
     ]
    }
   ],
   "source": [
    "# Parse the XML\n",
    "parser = FullTextXMLParser(xml_content)\n",
    "\n",
    "# Build entities\n",
    "paper, authors, sections, tables, references = build_paper_entities(parser)\n",
    "\n",
    "print(f\"Paper: {paper.title}\")\n",
    "print(f\"PMCID: {paper.pmcid}\")\n",
    "print(f\"DOI: {paper.doi}\")\n",
    "print(f\"\\nStatistics:\")\n",
    "print(f\"  Authors: {len(authors)}\")\n",
    "print(f\"  Sections: {len(sections)}\")\n",
    "print(f\"  Tables: {len(tables)}\")\n",
    "print(f\"  References: {len(references)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Normalize and Validate Entities\n",
    "\n",
    "Before converting to RDF, normalize and validate the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DOI before normalization: 10.1371/journal.pone.0037718\n",
      "DOI after normalization: 10.1371/journal.pone.0037718\n",
      "✓ Paper validation passed\n",
      "✓ All 8 authors validated\n"
     ]
    }
   ],
   "source": [
    "# Show DOI before normalization\n",
    "print(f\"DOI before normalization: {paper.doi}\")\n",
    "\n",
    "# Normalize paper\n",
    "paper.normalize()\n",
    "print(f\"DOI after normalization: {paper.doi}\")\n",
    "\n",
    "# Validate paper\n",
    "try:\n",
    "    paper.validate()\n",
    "    print(\"✓ Paper validation passed\")\n",
    "except ValueError as e:\n",
    "    print(f\"✗ Paper validation failed: {e}\")\n",
    "\n",
    "# Normalize and validate all authors\n",
    "for author in authors:\n",
    "    author.normalize()\n",
    "    try:\n",
    "        author.validate()\n",
    "    except ValueError as e:\n",
    "        print(f\"✗ Author validation failed: {e}\")\n",
    "\n",
    "print(f\"✓ All {len(authors)} authors validated\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Convert to RDF\n",
    "\n",
    "Now convert the entities to RDF triples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paper URI: http://example.org/data/paperentity/3359999\n",
      "Triples after adding paper: 11\n",
      "\n",
      "First author URI: http://example.org/data/authorentity/6b361df5-2778-43f0-83bd-d02ad52035a8\n",
      "Triples after adding 8 authors: 35\n",
      "Triples after adding 3 sections: 50\n",
      "Triples after adding 2 tables: 56\n",
      "\n",
      "Total triples in graph: 89\n"
     ]
    }
   ],
   "source": [
    "# Initialize RDF mapper and graph\n",
    "mapper = RDFMapper()\n",
    "g = Graph()\n",
    "\n",
    "# Bind namespaces for prettier output\n",
    "g.bind(\"dct\", Namespace(\"http://purl.org/dc/terms/\"))\n",
    "g.bind(\"bibo\", Namespace(\"http://purl.org/ontology/bibo/\"))\n",
    "g.bind(\"foaf\", Namespace(\"http://xmlns.com/foaf/0.1/\"))\n",
    "g.bind(\"prov\", Namespace(\"http://www.w3.org/ns/prov#\"))\n",
    "g.bind(\"nif\", Namespace(\"http://persistence.uni-leipzig.org/nlp2rdf/ontologies/nif-core#\"))\n",
    "\n",
    "# Add paper to graph\n",
    "paper_uri = paper.to_rdf(g, mapper=mapper)\n",
    "print(f\"Paper URI: {paper_uri}\")\n",
    "print(f\"Triples after adding paper: {len(g)}\")\n",
    "\n",
    "# Add authors\n",
    "for i, author in enumerate(authors):\n",
    "    author_uri = author.to_rdf(g, mapper=mapper)\n",
    "    if i == 0:\n",
    "        print(f\"\\nFirst author URI: {author_uri}\")\n",
    "\n",
    "print(f\"Triples after adding {len(authors)} authors: {len(g)}\")\n",
    "\n",
    "# Add sections\n",
    "for section in sections[:3]:  # Add first 3 sections for demo\n",
    "    section.to_rdf(g, mapper=mapper)\n",
    "\n",
    "print(f\"Triples after adding 3 sections: {len(g)}\")\n",
    "\n",
    "# Add tables\n",
    "for table in tables:\n",
    "    table.to_rdf(g, mapper=mapper)\n",
    "\n",
    "print(f\"Triples after adding {len(tables)} tables: {len(g)}\")\n",
    "\n",
    "# Add references\n",
    "for reference in references[:5]:  # Add first 5 references for demo\n",
    "    reference.to_rdf(g, mapper=mapper)\n",
    "\n",
    "print(f\"\\nTotal triples in graph: {len(g)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Serialize to Turtle Format\n",
    "\n",
    "Let's view the RDF in Turtle format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RDF/Turtle Output (first 1000 characters):\n",
      "============================================================\n",
      "@prefix bibo: <http://purl.org/ontology/bibo/> .\n",
      "@prefix dct: <http://purl.org/dc/terms/> .\n",
      "@prefix foaf: <http://xmlns.com/foaf/0.1/> .\n",
      "@prefix nif: <http://persistence.uni-leipzig.org/nlp2rdf/ontologies/nif-core#> .\n",
      "@prefix prov: <http://www.w3.org/ns/prov#> .\n",
      "@prefix rdfs: <http://www.w3.org/2000/01/rdf-schema#> .\n",
      "\n",
      "<http://example.org/data/authorentity/25811a81-b665-4c8e-b324-f7a1ecb47bfb> a foaf:Person ;\n",
      "    rdfs:label \"Lynne Margaret Michael\" ;\n",
      "    foaf:name \"Lynne Margaret Michael\" .\n",
      "\n",
      "<http://example.org/data/authorentity/3a1ecb78-b03e-4502-93f3-6d5c315eef26> a foaf:Person ;\n",
      "    rdfs:label \"Stephen Rakem Werre\" ;\n",
      "    foaf:name \"Stephen Rakem Werre\" .\n",
      "\n",
      "<http://example.org/data/authorentity/6b361df5-2778-43f0-83bd-d02ad52035a8> a foaf:Person ;\n",
      "    rdfs:label \"Rosina Claudia Krecek\" ;\n",
      "    foaf:name \"Rosina Claudia Krecek\" .\n",
      "\n",
      "<http://example.org/data/authorentity/705e54b5-b176-4fcd-b80f-530fa2ab26d7> a foaf:Person ;\n",
      "    rdfs:label \"Hamish Mohammed\" ;\n",
      "    foaf:name \"Hamish Mohammed\" .\n",
      "...\n",
      "\n",
      "Total output length: 11982 characters\n"
     ]
    }
   ],
   "source": [
    "# Serialize to Turtle\n",
    "ttl = mapper.serialize_graph(g, format=\"turtle\")\n",
    "\n",
    "# Display first 1000 characters\n",
    "print(\"RDF/Turtle Output (first 1000 characters):\")\n",
    "print(\"=\" * 60)\n",
    "print(ttl[:1000])\n",
    "print(\"...\")\n",
    "print(f\"\\nTotal output length: {len(ttl)} characters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Query the RDF Graph with SPARQL\n",
    "\n",
    "Now we can query the graph using SPARQL:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 1: Paper Metadata\n",
      "============================================================\n",
      "Paper: http://example.org/data/paperentity/3359999\n",
      "Title: Risk Factors of Porcine Cysticercosis in the Eastern Cape Province, South Africa\n",
      "DOI: 10.1371/journal.pone.0037718\n",
      "Journal: PLoS ONE\n"
     ]
    }
   ],
   "source": [
    "# Query 1: Get paper metadata\n",
    "query1 = \"\"\"\n",
    "PREFIX bibo: <http://purl.org/ontology/bibo/>\n",
    "PREFIX dct: <http://purl.org/dc/terms/>\n",
    "PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
    "\n",
    "SELECT ?paper ?title ?doi ?journal\n",
    "WHERE {\n",
    "    ?paper a bibo:AcademicArticle .\n",
    "    ?paper dct:title ?title .\n",
    "    OPTIONAL { ?paper bibo:doi ?doi }\n",
    "    OPTIONAL { ?paper bibo:journal ?journal }\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "print(\"Query 1: Paper Metadata\")\n",
    "print(\"=\" * 60)\n",
    "results = g.query(query1)\n",
    "for row in results:\n",
    "    print(f\"Paper: {row.paper}\")\n",
    "    print(f\"Title: {row.title}\")\n",
    "    print(f\"DOI: {row.doi}\")\n",
    "    print(f\"Journal: {row.journal}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Query 2: Authors\n",
      "============================================================\n",
      "1. Rosina Claudia Krecek\n",
      "2. Hamish Mohammed\n",
      "3. Lynne Margaret Michael\n",
      "4. Peter Mullineaux Schantz\n",
      "5. Lulama Ntanjana\n",
      "6. Liesl Morey\n",
      "7. Stephen Rakem Werre\n",
      "8. Arve Lee Willingham\n"
     ]
    }
   ],
   "source": [
    "# Query 2: Get all authors\n",
    "query2 = \"\"\"\n",
    "PREFIX foaf: <http://xmlns.com/foaf/0.1/>\n",
    "PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
    "\n",
    "SELECT ?author ?name\n",
    "WHERE {\n",
    "    ?author a foaf:Person .\n",
    "    ?author foaf:name ?name .\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "print(\"\\nQuery 2: Authors\")\n",
    "print(\"=\" * 60)\n",
    "results = g.query(query2)\n",
    "for i, row in enumerate(results, 1):\n",
    "    print(f\"{i}. {row.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Query 3: Document Sections\n",
      "============================================================\n",
      "1. Introduction\n",
      "   Content preview: A high prevalence of Taenia solium taeniosis/cysticercosis is reported from some countries in Africa...\n",
      "\n",
      "2. Materials and Methods\n",
      "   Content preview: This study was carried out from February to June 2003, in the six veterinary districts of the Alfred...\n",
      "\n",
      "3. Study design and population\n",
      "   Content preview: This study was carried out from February to June 2003, in the six veterinary districts of the Alfred...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Query 3: Get document sections\n",
    "query3 = \"\"\"\n",
    "PREFIX bibo: <http://purl.org/ontology/bibo/>\n",
    "PREFIX dct: <http://purl.org/dc/terms/>\n",
    "PREFIX nif: <http://persistence.uni-leipzig.org/nlp2rdf/ontologies/nif-core#>\n",
    "\n",
    "SELECT ?section ?title ?content\n",
    "WHERE {\n",
    "    ?section a bibo:DocumentPart .\n",
    "    ?section dct:title ?title .\n",
    "    OPTIONAL { ?section nif:isString ?content }\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "print(\"\\nQuery 3: Document Sections\")\n",
    "print(\"=\" * 60)\n",
    "results = g.query(query3)\n",
    "for i, row in enumerate(results, 1):\n",
    "    content_preview = str(row.content)[:100] if row.content else \"No content\"\n",
    "    print(f\"{i}. {row.title}\")\n",
    "    print(f\"   Content preview: {content_preview}...\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Export to Different RDF Formats\n",
    "\n",
    "RDF can be serialized to various formats:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TURTLE format: 11982 characters\n",
      "First 200 characters:\n",
      "@prefix bibo: <http://purl.org/ontology/bibo/> .\n",
      "@prefix dct: <http://purl.org/dc/terms/> .\n",
      "@prefix foaf: <http://xmlns.com/foaf/0.1/> .\n",
      "@prefix nif: <http://persistence.uni-leipzig.org/nlp2rdf/ontolo\n",
      "...\n",
      "\n",
      "XML format: 14923 characters\n",
      "First 200 characters:\n",
      "<?xml version=\"1.0\" encoding=\"utf-8\"?>\n",
      "<rdf:RDF\n",
      "   xmlns:bibo=\"http://purl.org/ontology/bibo/\"\n",
      "   xmlns:dct=\"http://purl.org/dc/terms/\"\n",
      "   xmlns:foaf=\"http://xmlns.com/foaf/0.1/\"\n",
      "   xmlns:nif=\"http://\n",
      "...\n",
      "\n",
      "JSON-LD format: 17860 characters\n",
      "First 200 characters:\n",
      "[\n",
      "  {\n",
      "    \"@id\": \"http://example.org/data/referenceentity/4d7eefa8-da13-4a61-8627-2bfa929279cc\",\n",
      "    \"@type\": [\n",
      "      \"http://purl.org/ontology/bibo/Document\"\n",
      "    ],\n",
      "    \"http://purl.org/dc/terms/crea\n",
      "...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Export to different formats\n",
    "formats = [\"turtle\", \"xml\", \"json-ld\"]\n",
    "\n",
    "for fmt in formats:\n",
    "    output = mapper.serialize_graph(g, format=fmt)\n",
    "    print(f\"{fmt.upper()} format: {len(output)} characters\")\n",
    "    print(f\"First 200 characters:\")\n",
    "    print(output[:200])\n",
    "    print(\"...\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Save to Files\n",
    "\n",
    "Save the RDF to files for loading into a triple store:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Turtle: /tmp/rdf_output/paper_3359999.ttl\n",
      "Saved JSON-LD: /tmp/rdf_output/paper_3359999.jsonld\n",
      "Saved RDF/XML: /tmp/rdf_output/paper_3359999.rdf\n",
      "\n",
      "All files saved to: /tmp/rdf_output\n"
     ]
    }
   ],
   "source": [
    "# Save to files\n",
    "output_dir = \"/tmp/rdf_output\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Save as Turtle\n",
    "ttl_path = f\"{output_dir}/paper_{paper.pmcid}.ttl\"\n",
    "mapper.serialize_graph(g, format=\"turtle\", destination=ttl_path)\n",
    "print(f\"Saved Turtle: {ttl_path}\")\n",
    "\n",
    "# Save as JSON-LD\n",
    "jsonld_path = f\"{output_dir}/paper_{paper.pmcid}.jsonld\"\n",
    "mapper.serialize_graph(g, format=\"json-ld\", destination=jsonld_path)\n",
    "print(f\"Saved JSON-LD: {jsonld_path}\")\n",
    "\n",
    "# Save as RDF/XML\n",
    "xml_path = f\"{output_dir}/paper_{paper.pmcid}.rdf\"\n",
    "mapper.serialize_graph(g, format=\"xml\", destination=xml_path)\n",
    "print(f\"Saved RDF/XML: {xml_path}\")\n",
    "\n",
    "print(f\"\\nAll files saved to: {output_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Graph Statistics\n",
    "\n",
    "Let's analyze the generated RDF graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entity Type Distribution:\n",
      "============================================================\n",
      "Person: <built-in method count of ResultRow object at 0x707df7bcb750>\n",
      "Document: <built-in method count of ResultRow object at 0x707df7a9f160>\n",
      "DocumentPart: <built-in method count of ResultRow object at 0x707df7bcb750>\n",
      "Context: <built-in method count of ResultRow object at 0x707df7a9f160>\n",
      "Table: <built-in method count of ResultRow object at 0x707df7bcb750>\n",
      "AcademicArticle: <built-in method count of ResultRow object at 0x707df7a9f160>\n",
      "\n",
      "Total triples: 89\n",
      "Total unique subjects: 19\n",
      "Total unique predicates: 16\n",
      "Total unique objects: 51\n"
     ]
    }
   ],
   "source": [
    "# Count entities by type\n",
    "from collections import Counter\n",
    "\n",
    "# Query to get all types\n",
    "type_query = \"\"\"\n",
    "SELECT ?type (COUNT(?entity) as ?count)\n",
    "WHERE {\n",
    "    ?entity a ?type .\n",
    "}\n",
    "GROUP BY ?type\n",
    "ORDER BY DESC(?count)\n",
    "\"\"\"\n",
    "\n",
    "print(\"Entity Type Distribution:\")\n",
    "print(\"=\" * 60)\n",
    "results = g.query(type_query)\n",
    "for row in results:\n",
    "    type_name = str(row.type).split(\"/\")[-1].split(\"#\")[-1]\n",
    "    print(f\"{type_name}: {row.count}\")\n",
    "\n",
    "print(f\"\\nTotal triples: {len(g)}\")\n",
    "print(f\"Total unique subjects: {len(set(g.subjects()))}\")\n",
    "print(f\"Total unique predicates: {len(set(g.predicates()))}\")\n",
    "print(f\"Total unique objects: {len(set(g.objects()))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Using the CLI Tool\n",
    "\n",
    "For batch processing, use the CLI tool:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Command-line usage:\n",
      "\n",
      "# Convert single file to Turtle and JSON\n",
      "python scripts/xml_to_rdf.py input.xml --ttl output.ttl --json output.json -v\n",
      "\n",
      "# Convert multiple files\n",
      "for file in *.xml; do\n",
      "    python scripts/xml_to_rdf.py \"$file\" --ttl \"${file%.xml}.ttl\" -v\n",
      "done\n",
      "\n",
      "# Use custom RDF mapping configuration\n",
      "python scripts/xml_to_rdf.py input.xml --ttl output.ttl --config custom_map.yml\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Example CLI usage (run in terminal)\n",
    "print(\"\"\"\n",
    "Command-line usage:\n",
    "\n",
    "# Convert single file to Turtle and JSON\n",
    "python scripts/xml_to_rdf.py input.xml --ttl output.ttl --json output.json -v\n",
    "\n",
    "# Convert multiple files\n",
    "for file in *.xml; do\n",
    "    python scripts/xml_to_rdf.py \"$file\" --ttl \"${file%.xml}.ttl\" -v\n",
    "done\n",
    "\n",
    "# Use custom RDF mapping configuration\n",
    "python scripts/xml_to_rdf.py input.xml --ttl output.ttl --config custom_map.yml\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated:\n",
    "\n",
    "1. Loading and parsing PMC XML files\n",
    "2. Building typed entity models\n",
    "3. Normalizing and validating data\n",
    "4. Converting to RDF with ontology alignment\n",
    "5. Querying RDF with SPARQL\n",
    "6. Exporting to multiple RDF formats\n",
    "7. Saving for triple store integration\n",
    "8. Analyzing graph statistics\n",
    "9. Using the CLI tool for batch processing\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "- Load RDF into GraphDB, Blazegraph, or other triple stores\n",
    "- Validate with SHACL shapes (see `shacl/pub.shacl.ttl`)\n",
    "- Extend ontology mappings in `conf/rdf_map.yml`\n",
    "- Build federated queries across multiple papers\n",
    "- Integrate with existing knowledge graphs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyeuropepmc-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
