{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RDF Conversion Workflow Demo\n",
    "\n",
    "This notebook demonstrates converting PMC XML articles to RDF for integration with knowledge graphs.\n",
    "\n",
    "## Use Cases\n",
    "\n",
    "- **Semantic Integration**: Integrate scientific literature with knowledge graphs\n",
    "- **SPARQL Queries**: Query literature data using SPARQL\n",
    "- **Ontology Alignment**: Align to standard ontologies (BIBO, FOAF, DCT)\n",
    "- **GraphDB Loading**: Prepare data for triple stores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required modules\n",
    "from pyeuropepmc.processing.fulltext_parser import FullTextXMLParser\n",
    "from pyeuropepmc.builders import build_paper_entities\n",
    "from pyeuropepmc.mappers import RDFMapper\n",
    "from rdflib import Graph, Namespace\n",
    "from rdflib.namespace import RDF, RDFS\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load and Parse a PMC XML File\n",
    "\n",
    "Let's start by loading a real PMC article:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded XML file: 64374 characters\n"
     ]
    }
   ],
   "source": [
    "# Load a fixture file\n",
    "fixture_path = \"../tests/fixtures/fulltext_downloads/PMC3359999.xml\"\n",
    "\n",
    "if os.path.exists(fixture_path):\n",
    "    with open(fixture_path, 'r') as f:\n",
    "        xml_content = f.read()\n",
    "    print(f\"Loaded XML file: {len(xml_content)} characters\")\n",
    "else:\n",
    "    print(f\"File not found: {fixture_path}\")\n",
    "    print(\"Please adjust the path to point to a PMC XML file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paper: Risk Factors of Porcine Cysticercosis in the Eastern Cape Province, South Africa\n",
      "PMCID: 3359999\n",
      "DOI: 10.1371/journal.pone.0037718\n",
      "\n",
      "Statistics:\n",
      "  Authors: 8\n",
      "  Sections: 10\n",
      "  Tables: 2\n",
      "  Figures: 0\n",
      "  References: 28\n"
     ]
    }
   ],
   "source": [
    "# Parse the XML\n",
    "parser = FullTextXMLParser(xml_content)\n",
    "\n",
    "# Build entities\n",
    "paper, authors, sections, tables, figures, references = build_paper_entities(parser)\n",
    "\n",
    "print(f\"Paper: {paper.title}\")\n",
    "print(f\"PMCID: {paper.pmcid}\")\n",
    "print(f\"DOI: {paper.doi}\")\n",
    "print(f\"\\nStatistics:\")\n",
    "print(f\"  Authors: {len(authors)}\")\n",
    "print(f\"  Sections: {len(sections)}\")\n",
    "print(f\"  Tables: {len(tables)}\")\n",
    "print(f\"  Figures: {len(figures)}\")\n",
    "print(f\"  References: {len(references)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Normalize and Validate Entities\n",
    "\n",
    "Before converting to RDF, normalize and validate the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DOI before normalization: 10.1371/journal.pone.0037718\n",
      "DOI after normalization: 10.1371/journal.pone.0037718\n",
      "✓ Paper validation passed\n",
      "✓ All 8 authors validated\n"
     ]
    }
   ],
   "source": [
    "# Show DOI before normalization\n",
    "print(f\"DOI before normalization: {paper.doi}\")\n",
    "\n",
    "# Normalize paper\n",
    "paper.normalize()\n",
    "print(f\"DOI after normalization: {paper.doi}\")\n",
    "\n",
    "# Validate paper\n",
    "try:\n",
    "    paper.validate()\n",
    "    print(\"✓ Paper validation passed\")\n",
    "except ValueError as e:\n",
    "    print(f\"✗ Paper validation failed: {e}\")\n",
    "\n",
    "# Normalize and validate all authors\n",
    "for author in authors:\n",
    "    author.normalize()\n",
    "    try:\n",
    "        author.validate()\n",
    "    except ValueError as e:\n",
    "        print(f\"✗ Author validation failed: {e}\")\n",
    "\n",
    "print(f\"✓ All {len(authors)} authors validated\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Convert to RDF\n",
    "\n",
    "Now convert the entities to RDF triples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paper URI: https://doi.org/10.1371/journal.pone.0037718\n",
      "Triples after adding paper: 13\n",
      "\n",
      "First author URI: http://example.org/data/author/rosina-claudia-krecek\n",
      "Triples after adding 8 authors: 123\n",
      "Triples after adding 3 sections: 141\n",
      "Triples after adding 2 tables: 438\n",
      "\n",
      "Total triples in graph: 478\n"
     ]
    }
   ],
   "source": [
    "# Initialize RDF mapper and graph\n",
    "mapper = RDFMapper()\n",
    "g = Graph()\n",
    "\n",
    "# Bind namespaces for proper serialization\n",
    "mapper._bind_namespaces(g)\n",
    "\n",
    "# Add paper to graph\n",
    "paper_uri = paper.to_rdf(g, mapper=mapper)\n",
    "print(f\"Paper URI: {paper_uri}\")\n",
    "print(f\"Triples after adding paper: {len(g)}\")\n",
    "\n",
    "# Add authors\n",
    "for i, author in enumerate(authors):\n",
    "    author_uri = author.to_rdf(g, mapper=mapper)\n",
    "    if i == 0:\n",
    "        print(f\"\\nFirst author URI: {author_uri}\")\n",
    "\n",
    "print(f\"Triples after adding {len(authors)} authors: {len(g)}\")\n",
    "\n",
    "# Add sections\n",
    "for section in sections[:3]:  # Add first 3 sections for demo\n",
    "    section.to_rdf(g, mapper=mapper)\n",
    "\n",
    "print(f\"Triples after adding 3 sections: {len(g)}\")\n",
    "\n",
    "# Add tables\n",
    "for table in tables:\n",
    "    table.to_rdf(g, mapper=mapper)\n",
    "\n",
    "print(f\"Triples after adding {len(tables)} tables: {len(g)}\")\n",
    "\n",
    "# Add references\n",
    "for reference in references[:5]:  # Add first 5 references for demo\n",
    "    reference.to_rdf(g, mapper=mapper)\n",
    "\n",
    "print(f\"\\nTotal triples in graph: {len(g)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Serialize to Turtle Format\n",
    "\n",
    "Let's view the RDF in Turtle format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RDF/Turtle Output (first 1000 characters):\n",
      "============================================================\n",
      "@prefix bibo: <http://purl.org/ontology/bibo/> .\n",
      "@prefix dcterms: <http://purl.org/dc/terms/> .\n",
      "@prefix ex: <http://example.org/> .\n",
      "@prefix foaf: <http://xmlns.com/foaf/0.1/> .\n",
      "@prefix nif: <http://persistence.uni-leipzig.org/nlp2rdf/ontologies/nif-core#> .\n",
      "@prefix org: <http://www.w3.org/ns/org#> .\n",
      "@prefix owl: <http://www.w3.org/2002/07/owl#> .\n",
      "@prefix prov: <http://www.w3.org/ns/prov#> .\n",
      "@prefix rdfs: <http://www.w3.org/2000/01/rdf-schema#> .\n",
      "@prefix skos: <http://www.w3.org/2004/02/skos/core#> .\n",
      "@prefix xsd: <http://www.w3.org/2001/XMLSchema#> .\n",
      "\n",
      "<http://example.org/data/reference/41f7a5d8-016f-4aae-91b2-c357291e203e> a bibo:Document ;\n",
      "    dcterms:title \"Seroprevalence of antibodies against Taenia solium cysticerci among refugees resettled in United States.\" ;\n",
      "    bibo:journalTitle \"Emerg Infect Dis\" ;\n",
      "    prov:generatedAtTime \"2025-11-25T12:04:33.235435\" ;\n",
      "    prov:wasGeneratedBy \"pyeuropepmc_parser\" .\n",
      "\n",
      "<http://example.org/data/reference/56528e51-1241-4184-af20-0ca523f7c50c> a bib\n",
      "...\n",
      "\n",
      "Total output length: 33825 characters\n"
     ]
    }
   ],
   "source": [
    "# Serialize to Turtle\n",
    "ttl = mapper.serialize_graph(g, format=\"turtle\")\n",
    "\n",
    "# Display first 1000 characters\n",
    "print(\"RDF/Turtle Output (first 1000 characters):\")\n",
    "print(\"=\" * 60)\n",
    "print(ttl[:1000])\n",
    "print(\"...\")\n",
    "print(f\"\\nTotal output length: {len(ttl)} characters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Knowledge Graph Structure Options\n",
    "\n",
    "PyEuropePMC supports different knowledge graph structures for different use cases:\n",
    "\n",
    "- **Complete KG**: All entities (metadata + content) - best for comprehensive analysis\n",
    "- **Metadata KG**: Only bibliographic metadata (papers, authors, institutions) - best for citation networks\n",
    "- **Content KG**: Only document content (sections, references, tables) - best for text analysis\n",
    "\n",
    "Let's demonstrate each approach:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entities data prepared:\n",
      "  Paper: Risk Factors of Porcine Cysticercosis in the Eastern Cape Province, South Africa\n",
      "  Authors: 8\n",
      "  Sections: 10\n",
      "  Tables: 2\n",
      "  Figures: 0\n",
      "  References: 28\n"
     ]
    }
   ],
   "source": [
    "# Prepare entities data in the expected format\n",
    "entities_data = {\n",
    "    paper.doi or paper.pmcid: {\n",
    "        \"entity\": paper,\n",
    "        \"related_entities\": {\n",
    "            \"authors\": authors,\n",
    "            \"sections\": sections,\n",
    "            \"tables\": tables,\n",
    "            \"figures\": figures,\n",
    "            \"references\": references,\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"Entities data prepared:\")\n",
    "print(f\"  Paper: {paper.title}\")\n",
    "print(f\"  Authors: {len(authors)}\")\n",
    "print(f\"  Sections: {len(sections)}\")\n",
    "print(f\"  Tables: {len(tables)}\")\n",
    "print(f\"  Figures: {len(figures)}\")\n",
    "print(f\"  References: {len(references)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Metadata-Only Knowledge Graph...\n",
      "Converting to RDF: 10.1371/journal.pone.0037718 (paper)\n",
      "  [OK] Successfully converted to RDF (139 triples)\n",
      "  [OK] Saved to: /tmp/rdf_output/metadata_paper_10_1371_journal_pone_0037718.ttl\n",
      "Successfully converted 1 entities to RDF\n",
      "Metadata KG saved: 1 graphs\n",
      "  10.1371/journal.pone.0037718: 139 triples\n"
     ]
    }
   ],
   "source": [
    "# Create metadata-only knowledge graph\n",
    "print(\"Creating Metadata-Only Knowledge Graph...\")\n",
    "metadata_graphs = mapper.save_metadata_rdf(\n",
    "    entities_data=entities_data,\n",
    "    output_dir=\"/tmp/rdf_output\",\n",
    "    extraction_info={\"method\": \"notebook_demo\", \"timestamp\": \"2024-01-01T00:00:00Z\"}\n",
    ")\n",
    "\n",
    "print(f\"Metadata KG saved: {len(metadata_graphs)} graphs\")\n",
    "for identifier, g in metadata_graphs.items():\n",
    "    print(f\"  {identifier}: {len(g)} triples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Creating Content-Only Knowledge Graph...\n",
      "Converting to RDF: 10.1371/journal.pone.0037718 (paper)\n",
      "  [OK] Successfully converted to RDF (680 triples)\n",
      "  [OK] Saved to: /tmp/rdf_output/content_paper_10_1371_journal_pone_0037718.ttl\n",
      "Successfully converted 1 entities to RDF\n",
      "Content KG saved: 1 graphs\n",
      "  10.1371/journal.pone.0037718: 680 triples\n"
     ]
    }
   ],
   "source": [
    "# Create content-only knowledge graph\n",
    "print(\"\\nCreating Content-Only Knowledge Graph...\")\n",
    "content_graphs = mapper.save_content_rdf(\n",
    "    entities_data=entities_data,\n",
    "    output_dir=\"/tmp/rdf_output\",\n",
    "    extraction_info={\"method\": \"notebook_demo\", \"timestamp\": \"2024-01-01T00:00:00Z\"}\n",
    ")\n",
    "\n",
    "print(f\"Content KG saved: {len(content_graphs)} graphs\")\n",
    "for identifier, g in content_graphs.items():\n",
    "    print(f\"  {identifier}: {len(g)} triples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Creating Complete Knowledge Graph...\n",
      "Converting to RDF: 10.1371/journal.pone.0037718 (paper)\n",
      "  [OK] Successfully converted to RDF (806 triples)\n",
      "  [OK] Saved to: /tmp/rdf_output/paper_10_1371_journal_pone_0037718.ttl\n",
      "Successfully converted 1 entities to RDF\n",
      "Complete KG saved: 1 graphs\n",
      "  10.1371/journal.pone.0037718: 806 triples\n",
      "  [OK] Successfully converted to RDF (806 triples)\n",
      "  [OK] Saved to: /tmp/rdf_output/paper_10_1371_journal_pone_0037718.ttl\n",
      "Successfully converted 1 entities to RDF\n",
      "Complete KG saved: 1 graphs\n",
      "  10.1371/journal.pone.0037718: 806 triples\n"
     ]
    }
   ],
   "source": [
    "# Create complete knowledge graph\n",
    "print(\"\\nCreating Complete Knowledge Graph...\")\n",
    "complete_graphs = mapper.save_complete_rdf(\n",
    "    entities_data=entities_data,\n",
    "    output_dir=\"/tmp/rdf_output\",\n",
    "    extraction_info={\"method\": \"notebook_demo\", \"timestamp\": \"2024-01-01T00:00:00Z\"}\n",
    ")\n",
    "\n",
    "print(f\"Complete KG saved: {len(complete_graphs)} graphs\")\n",
    "for identifier, g in complete_graphs.items():\n",
    "    print(f\"  {identifier}: {len(g)} triples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Knowledge Graph Structure Comparison:\n",
      "============================================================\n",
      "Metadata KG: file not found\n",
      "Content KG: file not found\n",
      "Complete KG: file not found\n"
     ]
    }
   ],
   "source": [
    "# Compare the different KG structures\n",
    "print(\"Knowledge Graph Structure Comparison:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Load and analyze each graph\n",
    "import os\n",
    "from rdflib import Graph\n",
    "\n",
    "graphs = {\n",
    "    \"Metadata\": Graph(),\n",
    "    \"Content\": Graph(),\n",
    "    \"Complete\": Graph()\n",
    "}\n",
    "\n",
    "# Load the saved graphs\n",
    "for kg_type in graphs.keys():\n",
    "    filename = f\"/tmp/rdf_output/{kg_type.lower()}_{paper.doi or paper.pmcid}.ttl\"\n",
    "    if os.path.exists(filename):\n",
    "        graphs[kg_type].parse(filename, format=\"turtle\")\n",
    "        print(f\"{kg_type} KG: {len(graphs[kg_type])} triples\")\n",
    "    else:\n",
    "        print(f\"{kg_type} KG: file not found\")\n",
    "\n",
    "# Query entity types in each graph\n",
    "for kg_type, g in graphs.items():\n",
    "    if len(g) > 0:\n",
    "        type_query = \"\"\"\n",
    "        SELECT ?type (COUNT(?entity) as ?count)\n",
    "        WHERE {\n",
    "            ?entity a ?type .\n",
    "        }\n",
    "        GROUP BY ?type\n",
    "        ORDER BY DESC(?count)\n",
    "        \"\"\"\n",
    "\n",
    "        print(f\"\\n{kg_type} KG Entity Types:\")\n",
    "        results = g.query(type_query)\n",
    "        for row in results:\n",
    "            type_name = str(row.type).split(\"/\")[-1].split(\"#\")[-1]\n",
    "            print(f\"  {type_name}: {row.count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Configured KG Type:\n",
      "Converting to RDF: 10.1371/journal.pone.0037718 (paper)\n",
      "  [OK] Successfully converted to RDF (139 triples)\n",
      "  [OK] Saved to: /tmp/rdf_output/metadata_paper_10_1371_journal_pone_0037718.ttl\n",
      "Successfully converted 1 entities to RDF\n",
      "Configured KG saved: 1 graphs\n"
     ]
    }
   ],
   "source": [
    "# Use the convenience save_rdf method with configuration\n",
    "print(\"Using Configured KG Type:\")\n",
    "\n",
    "# The mapper uses configuration from conf/rdf_map.yml\n",
    "# By default it's set to \"complete\", but you can override\n",
    "configured_graphs = mapper.save_rdf(\n",
    "    entities_data=entities_data,\n",
    "    output_dir=\"/tmp/rdf_output\",\n",
    "    kg_type=\"metadata\",  # Override to create metadata-only\n",
    "    extraction_info={\"method\": \"notebook_demo\"}\n",
    ")\n",
    "\n",
    "print(f\"Configured KG saved: {len(configured_graphs)} graphs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Export to Different RDF Formats\n",
    "\n",
    "RDF can be serialized to various formats:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TURTLE format: 1 characters\n",
      "First 200 characters:\n",
      "\n",
      "\n",
      "...\n",
      "\n",
      "XML format: 120 characters\n",
      "First 200 characters:\n",
      "<?xml version=\"1.0\" encoding=\"utf-8\"?>\n",
      "<rdf:RDF\n",
      "   xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\"\n",
      ">\n",
      "</rdf:RDF>\n",
      "\n",
      "...\n",
      "\n",
      "JSON-LD format: 2 characters\n",
      "First 200 characters:\n",
      "[]\n",
      "...\n",
      "\n",
      "JSON-LD format: 2 characters\n",
      "First 200 characters:\n",
      "[]\n",
      "...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Export to different formats\n",
    "formats = [\"turtle\", \"xml\", \"json-ld\"]\n",
    "\n",
    "for fmt in formats:\n",
    "    output = mapper.serialize_graph(g, format=fmt)\n",
    "    print(f\"{fmt.upper()} format: {len(output)} characters\")\n",
    "    print(f\"First 200 characters:\")\n",
    "    print(output[:200])\n",
    "    print(\"...\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Save to Files\n",
    "\n",
    "Save the RDF to files for loading into a triple store:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Turtle: /tmp/rdf_output/paper_PMC3359999.ttl\n",
      "Saved JSON-LD: /tmp/rdf_output/paper_PMC3359999.jsonld\n",
      "Saved RDF/XML: /tmp/rdf_output/paper_PMC3359999.rdf\n",
      "\n",
      "All files saved to: /tmp/rdf_output\n"
     ]
    }
   ],
   "source": [
    "# Save to files\n",
    "output_dir = \"/tmp/rdf_output\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Save as Turtle\n",
    "ttl_path = f\"{output_dir}/paper_{paper.pmcid}.ttl\"\n",
    "mapper.serialize_graph(g, format=\"turtle\", destination=ttl_path)\n",
    "print(f\"Saved Turtle: {ttl_path}\")\n",
    "\n",
    "# Save as JSON-LD\n",
    "jsonld_path = f\"{output_dir}/paper_{paper.pmcid}.jsonld\"\n",
    "mapper.serialize_graph(g, format=\"json-ld\", destination=jsonld_path)\n",
    "print(f\"Saved JSON-LD: {jsonld_path}\")\n",
    "\n",
    "# Save as RDF/XML\n",
    "xml_path = f\"{output_dir}/paper_{paper.pmcid}.rdf\"\n",
    "mapper.serialize_graph(g, format=\"xml\", destination=xml_path)\n",
    "print(f\"Saved RDF/XML: {xml_path}\")\n",
    "\n",
    "print(f\"\\nAll files saved to: {output_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Graph Statistics\n",
    "\n",
    "Let's analyze the generated RDF graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entity Type Distribution:\n",
      "============================================================\n",
      "\n",
      "Total triples: 0\n",
      "Total unique subjects: 0\n",
      "Total unique predicates: 0\n",
      "Total unique objects: 0\n",
      "\n",
      "Total triples: 0\n",
      "Total unique subjects: 0\n",
      "Total unique predicates: 0\n",
      "Total unique objects: 0\n"
     ]
    }
   ],
   "source": [
    "# Count entities by type\n",
    "from collections import Counter\n",
    "\n",
    "# Query to get all types\n",
    "type_query = \"\"\"\n",
    "SELECT ?type (COUNT(?entity) as ?count)\n",
    "WHERE {\n",
    "    ?entity a ?type .\n",
    "}\n",
    "GROUP BY ?type\n",
    "ORDER BY DESC(?count)\n",
    "\"\"\"\n",
    "\n",
    "print(\"Entity Type Distribution:\")\n",
    "print(\"=\" * 60)\n",
    "results = g.query(type_query)\n",
    "for row in results:\n",
    "    type_name = str(row.type).split(\"/\")[-1].split(\"#\")[-1]\n",
    "    print(f\"{type_name}: {row.count}\")\n",
    "\n",
    "print(f\"\\nTotal triples: {len(g)}\")\n",
    "print(f\"Total unique subjects: {len(set(g.subjects()))}\")\n",
    "print(f\"Total unique predicates: {len(set(g.predicates()))}\")\n",
    "print(f\"Total unique objects: {len(set(g.objects()))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Using the CLI Tool\n",
    "\n",
    "For batch processing, use the CLI tool:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Command-line usage:\n",
      "\n",
      "# Convert single file to Turtle and JSON\n",
      "python scripts/xml_to_rdf.py input.xml --ttl output.ttl --json output.json -v\n",
      "\n",
      "# Convert multiple files\n",
      "for file in *.xml; do\n",
      "    python scripts/xml_to_rdf.py \"$file\" --ttl \"${file%.xml}.ttl\" -v\n",
      "done\n",
      "\n",
      "# Use custom RDF mapping configuration\n",
      "python scripts/xml_to_rdf.py input.xml --ttl output.ttl --config custom_map.yml\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Example CLI usage (run in terminal)\n",
    "print(\"\"\"\n",
    "Command-line usage:\n",
    "\n",
    "# Convert single file to Turtle and JSON\n",
    "python scripts/xml_to_rdf.py input.xml --ttl output.ttl --json output.json -v\n",
    "\n",
    "# Convert multiple files\n",
    "for file in *.xml; do\n",
    "    python scripts/xml_to_rdf.py \"$file\" --ttl \"${file%.xml}.ttl\" -v\n",
    "done\n",
    "\n",
    "# Use custom RDF mapping configuration\n",
    "python scripts/xml_to_rdf.py input.xml --ttl output.ttl --config custom_map.yml\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated:\n",
    "\n",
    "1. Loading and parsing PMC XML files\n",
    "2. Building typed entity models\n",
    "3. Normalizing and validating data\n",
    "4. Converting to RDF with ontology alignment\n",
    "5. Querying RDF with SPARQL\n",
    "6. Exporting to multiple RDF formats\n",
    "7. Saving for triple store integration\n",
    "8. Analyzing graph statistics\n",
    "9. Using the CLI tool for batch processing\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "- Load RDF into GraphDB, Blazegraph, or other triple stores\n",
    "- Validate with SHACL shapes (see `shacl/pub.shacl.ttl`)\n",
    "- Extend ontology mappings in `conf/rdf_map.yml`\n",
    "- Build federated queries across multiple papers\n",
    "- Integrate with existing knowledge graphs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyeuropepmc-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
