{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7315dc27",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0040acce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyeuropepmc import SearchClient, FullTextClient\n",
    "import os\n",
    "import time\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e53728ef",
   "metadata": {},
   "source": [
    "## Search for Papers\n",
    "\n",
    "Let's search for papers that are likely to have XML full text available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edbebfca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize clients\n",
    "search_client = SearchClient()\n",
    "fulltext_client = FullTextClient()\n",
    "\n",
    "# Search for papers (open access papers are more likely to have XML)\n",
    "query = \"cancer immunotherapy OPEN_ACCESS:y\"\n",
    "\n",
    "print(f\"Searching for papers...\")\n",
    "print(f\"Query: {query}\")\n",
    "\n",
    "# Search for 30 papers\n",
    "results = search_client.search(query, limit=30)\n",
    "papers = results[\"resultList\"][\"result\"]\n",
    "\n",
    "print(f\"\\nFound {len(papers)} papers\")\n",
    "\n",
    "# Show sample papers\n",
    "for i, paper in enumerate(papers[:5], 1):\n",
    "    print(f\"{i}. {paper.get('title', 'No title')[:80]}...\")\n",
    "    print(f\"   DOI: {paper.get('doi', 'N/A')}\")\n",
    "    print(f\"   PMCID: {paper.get('pmcid', 'N/A')}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce139c7",
   "metadata": {},
   "source": [
    "## Download XML for All Papers\n",
    "\n",
    "Now let's download the XML content for all papers. We'll try each one and keep track of successes and failures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c31c26db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output directory\n",
    "output_dir = \"xml_downloads\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "print(f\"Downloading XML for {len(papers)} papers...\")\n",
    "print(f\"Saving to: {output_dir}/\")\n",
    "print()\n",
    "\n",
    "downloaded_files = []\n",
    "failed_downloads = []\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for i, paper in enumerate(papers, 1):\n",
    "    doi = paper.get('doi')\n",
    "    pmcid = paper.get('pmcid')\n",
    "\n",
    "    identifier = doi or pmcid or f\"paper_{i}\"\n",
    "    print(f\"[{i}/{len(papers)}] Downloading: {identifier}\")\n",
    "\n",
    "    try:\n",
    "        # Try to download XML\n",
    "        if pmcid:\n",
    "            xml_content = fulltext_client.download_xml(pmcid)\n",
    "        elif doi:\n",
    "            xml_content = fulltext_client.download_xml_by_doi(doi)\n",
    "        else:\n",
    "            raise ValueError(\"No PMCID or DOI available\")\n",
    "\n",
    "        # Save to file\n",
    "        safe_identifier = identifier.replace('/', '_').replace('.', '_').replace(':', '_')\n",
    "        filename = f\"{output_dir}/{safe_identifier}.xml\"\n",
    "\n",
    "        with open(filename, 'w', encoding='utf-8') as f:\n",
    "            f.write(xml_content)\n",
    "\n",
    "        downloaded_files.append(filename)\n",
    "        print(f\"  ✓ Saved: {filename} ({len(xml_content)} chars)\")\n",
    "\n",
    "    except Exception as e:\n",
    "        failed_downloads.append((identifier, str(e)))\n",
    "        print(f\"  ✗ Failed: {e}\")\n",
    "\n",
    "    # Small delay to be respectful to the API\n",
    "    time.sleep(0.5)\n",
    "\n",
    "end_time = time.time()\n",
    "duration = end_time - start_time\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"DOWNLOAD SUMMARY\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Total papers: {len(papers)}\")\n",
    "print(f\"Successful downloads: {len(downloaded_files)}\")\n",
    "print(f\"Failed downloads: {len(failed_downloads)}\")\n",
    "print(f\"Total time: {duration:.1f} seconds\")\n",
    "if len(papers) > 0:\n",
    "    print(f\"Average time per paper: {duration/len(papers):.1f} seconds\")\n",
    "\n",
    "if downloaded_files:\n",
    "    print(f\"\\nDownloaded files:\")\n",
    "    for filename in downloaded_files[:10]:  # Show first 10\n",
    "        print(f\"  - {filename}\")\n",
    "    if len(downloaded_files) > 10:\n",
    "        print(f\"  ... and {len(downloaded_files) - 10} more\")\n",
    "\n",
    "if failed_downloads:\n",
    "    print(f\"\\nFailed downloads:\")\n",
    "    for identifier, error in failed_downloads[:5]:  # Show first 5 failures\n",
    "        print(f\"  - {identifier}: {error}\")\n",
    "    if len(failed_downloads) > 5:\n",
    "        print(f\"  ... and {len(failed_downloads) - 5} more failures\")\n",
    "\n",
    "print(f\"\\nXML files saved in: {output_dir}/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a9ff0ff",
   "metadata": {},
   "source": [
    "## Verify Downloads\n",
    "\n",
    "Let's check that the downloads were successful by examining one of the files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5902756",
   "metadata": {},
   "outputs": [],
   "source": [
    "if downloaded_files:\n",
    "    # Check the first downloaded file\n",
    "    sample_file = downloaded_files[0]\n",
    "    print(f\"Checking sample file: {sample_file}\")\n",
    "\n",
    "    with open(sample_file, 'r', encoding='utf-8') as f:\n",
    "        content = f.read()\n",
    "\n",
    "    print(f\"File size: {len(content)} characters\")\n",
    "    print(f\"Contains '<article>': {'<article>' in content}\")\n",
    "    print(f\"Contains '<front>': {'<front>' in content}\")\n",
    "    print(f\"Contains '<body>': {'<body>' in content}\")\n",
    "\n",
    "    # Show first 500 characters\n",
    "    print(f\"\\nFirst 500 characters:\")\n",
    "    print(\"-\" * 40)\n",
    "    print(content[:500])\n",
    "    print(\"-\" * 40)\n",
    "else:\n",
    "    print(\"No files were downloaded successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6ca99cc",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated:\n",
    "\n",
    "1. Searching for papers that are likely to have XML full text\n",
    "2. Batch downloading XML content for multiple papers\n",
    "3. Saving XML files locally with organized filenames\n",
    "4. Error handling for failed downloads\n",
    "5. Download statistics and verification\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "- Parse the downloaded XML files using `FullTextXMLParser`\n",
    "- Convert to RDF using the `RDFMapper`\n",
    "- Build a knowledge graph from multiple papers\n",
    "- Analyze content across papers\n",
    "\n",
    "The downloaded XML files can now be used as input for further processing in other notebooks like the data models demo or RDF conversion demo."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
